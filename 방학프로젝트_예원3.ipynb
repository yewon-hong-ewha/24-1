{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObt3SUKzLOYuNWFvYFvxqj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4RY7cu9XaZn"
      },
      "source": [
        "### [AI vs Human 텍스트 판별 해커톤 -월간 데이콘 쇼츠](https://dacon.io/competitions/official/236178/overview/description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buTZtHJiXaZq"
      },
      "source": [
        "4일 후의 프로젝트를 위해 준비된 이 데이터셋에는 인간이 작성한 리뷰와 인공지능이 작성한 리뷰가 섞여 있습니다.\n",
        "\n",
        "하지만 어떤 리뷰가 인간에 의해 작성되었는지를 나타내는 레이블 대부분이 사라져버렸습니다.\n",
        "\n",
        "여러분의 임무는 일부 레이블이 남아있는 학습용 데이터셋을 활용하여,\n",
        "\n",
        "테스트 데이터셋의 네 개 리뷰 중 어떤 것이 실제 인간에 의해 작성된 것인지 정확하게 예측하는 것입니다!\n",
        "\n",
        "당신의 통찰력을 활용하여 테스트 데이터셋의 'label' 필드를 복구해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NzKXqYaXcVU",
        "outputId": "7a879203-bf76-46d3-ae4f-2c94dee6aa59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "J_VuJqaw7cQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)  # 이 부분이 pandas의 sample 함수에도 영향을 줍니다.\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed()"
      ],
      "metadata": {
        "id": "6iY2ZX-07ekW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "9RueDy2X7hsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/ESAA/OB/data/ai_vs_human_text/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/ESAA/OB/data/ai_vs_human_text/test.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/ESAA/OB/data/ai_vs_human_text/sample_submission.csv')\n",
        "print(train_data.shape, test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbpVVtfFzRIg",
        "outputId": "9988a971-b131-4847-d53a-586d56ac4f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 6) (1100, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melt the training data\n",
        "train_data_melted = train_data.melt(id_vars=['id', 'label'],\n",
        "                                    value_vars=['sentence1', 'sentence2', 'sentence3', 'sentence4'],\n",
        "                                    var_name='sentence_type', value_name='text')\n",
        "\n",
        "# Create binary labels: 1 if the sentence_type corresponds to the label, else 0\n",
        "train_data_melted['binary_label'] = (train_data_melted['sentence_type'] == train_data_melted['label']).astype(int)\n",
        "\n",
        "# Reshape the test data similarly\n",
        "test_data_melted = test_data.melt(id_vars=['id'],\n",
        "                                  value_vars=['sentence1', 'sentence2', 'sentence3', 'sentence4'],\n",
        "                                  var_name='sentence_type', value_name='text')\n"
      ],
      "metadata": {
        "id": "x7hTZsqB7u1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create binary labels: 1 if the sentence_type corresponds to the label, else 0\n",
        "train_data_melted['binary_label'] = (train_data_melted['sentence_type'] == train_data_melted['label']).astype(int)\n",
        "\n",
        "# Reshape the test data similarly\n",
        "test_data_melted = test_data.melt(id_vars=['id'],\n",
        "                                  value_vars=['sentence1', 'sentence2', 'sentence3', 'sentence4'],\n",
        "                                  var_name='sentence_type', value_name='text')"
      ],
      "metadata": {
        "id": "Uf-cRwBHOT7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "SEED = 42\n"
      ],
      "metadata": {
        "id": "6KzEPhRrOU1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels=None, tokenizer=None, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        ids = encoding['input_ids'].flatten()\n",
        "        mask = encoding['attention_mask'].flatten()\n",
        "        token_type_ids = encoding['token_type_ids'].flatten()\n",
        "\n",
        "        item = {\n",
        "            'ids': ids,\n",
        "            'mask': mask,\n",
        "            'token_type_ids': token_type_ids\n",
        "        }\n",
        "\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        return item"
      ],
      "metadata": {
        "id": "GLHh4YbaOWfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = BertModel.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "LyKNli_fOXgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add classification layer on top of BERT model\n",
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        pooled_output = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )[1]\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)\n",
        "\n",
        "model = BertClassifier(n_classes=2)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "j-4kVCPWOcEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets and data loaders\n",
        "train_dataset = TextDataset(\n",
        "    texts=train_data_melted['text'].values,\n",
        "    labels=train_data_melted['binary_label'].values,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataset = TextDataset(\n",
        "    texts=train_data_melted['text'].values,\n",
        "    labels=train_data_melted['binary_label'].values,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "02lAqVwxOdmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d['ids'].to(device)\n",
        "        attention_mask = d['mask'].to(device)\n",
        "        token_type_ids = d['token_type_ids'].to(device)\n",
        "        labels = d['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)"
      ],
      "metadata": {
        "id": "Tw3VzgM-Oglt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def eval_model(model, data_loader, device):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d['ids'].to(device)\n",
        "            attention_mask = d['mask'].to(device)\n",
        "            token_type_ids = d['token_type_ids'].to(device)\n",
        "            labels = d['labels'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)"
      ],
      "metadata": {
        "id": "0Er56fWkO_YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from collections import defaultdict\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=total_steps//EPOCHS, gamma=0.1)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        optimizer,\n",
        "        device,\n",
        "        scheduler\n",
        "    )\n",
        "\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_loader,\n",
        "        device\n",
        "    )\n",
        "\n",
        "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "        best_accuracy = val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lc-uLQ74C-s",
        "outputId": "f8e01988-027f-454e-e64f-07f3e00c118a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "----------\n",
            "Train loss 0.3714320814380279 accuracy 0.88\n",
            "Val   loss 0.07748464323007144 accuracy 1.0\n",
            "\n",
            "Epoch 2/3\n",
            "----------\n",
            "Train loss 0.07103936488811786 accuracy 1.0\n",
            "Val   loss 0.05315554371246925 accuracy 1.0\n",
            "\n",
            "Epoch 3/3\n",
            "----------\n",
            "Train loss 0.06026703004653637 accuracy 1.0\n",
            "Val   loss 0.051579076796770096 accuracy 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test data\n",
        "test_dataset = TextDataset(\n",
        "    texts=test_data_melted['text'].values,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load('best_model_state.bin'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gef1mp0bO6zO",
        "outputId": "c74af21c-7e9d-4856-9d2c-1f4051e2867e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def predict(model, data_loader):\n",
        "    model = model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d['ids'].to(device)\n",
        "            attention_mask = d['mask'].to(device)\n",
        "            token_type_ids = d['token_type_ids'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "\n",
        "            # Collect logits and apply softmax to get probabilities\n",
        "            logits = outputs\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            predictions.append(probs.cpu().numpy())\n",
        "\n",
        "    return np.vstack(predictions)"
      ],
      "metadata": {
        "id": "5D16zEyIOmdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get probabilities for each sentence in test set\n",
        "test_pred_probs = predict(model, test_loader)\n",
        "\n",
        "# Assign probabilities to test data\n",
        "test_data_melted['prob'] = test_pred_probs[:, 1]\n",
        "\n",
        "# Extract sentence number and adjust to be 1-4\n",
        "submission = test_data_melted[['id', 'sentence_type', 'prob']]\n",
        "submission['sentence_number'] = submission['sentence_type'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Select top 2 sentences for each id\n",
        "top2_sentences = submission.sort_values(['id', 'prob'], ascending=[True, False]).groupby('id').head(2)\n",
        "\n",
        "# Ensure labels are in the range 1-4\n",
        "top2_sentences['sentence_number'] = top2_sentences['sentence_number'] + 1\n",
        "\n",
        "# Create a DataFrame to hold the final submission\n",
        "final_submission = pd.DataFrame(top2_sentences['id'].unique(), columns=['id'])\n",
        "\n",
        "# Split the top 2 sentences into separate columns\n",
        "top2_sentences = top2_sentences.groupby('id')['sentence_number'].apply(list).reset_index()\n",
        "\n",
        "# Assign the top 2 sentence numbers to separate columns in final submission DataFrame\n",
        "final_submission['label1'] = top2_sentences['sentence_number'].apply(lambda x: x[0] if len(x) > 0 else np.nan)\n",
        "final_submission['label2'] = top2_sentences['sentence_number'].apply(lambda x: x[1] if len(x) > 1 else np.nan)\n",
        "\n",
        "# Save to CSV\n",
        "final_submission.to_csv('./submission.csv', index=False)\n",
        "\n",
        "final_submission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-PbnpUePOqB5",
        "outputId": "c15d4543-e28e-4358-fbca-10e905936c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  label1  label2\n",
              "0  TEST_0000       2       5\n",
              "1  TEST_0001       5       4\n",
              "2  TEST_0002       2       3\n",
              "3  TEST_0003       4       5\n",
              "4  TEST_0004       2       3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efa5c1f6-72a5-478e-9fc7-cfeb6e34a8c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efa5c1f6-72a5-478e-9fc7-cfeb6e34a8c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-efa5c1f6-72a5-478e-9fc7-cfeb6e34a8c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-efa5c1f6-72a5-478e-9fc7-cfeb6e34a8c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39b98ef3-75e3-472b-b790-687e3db6d267\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39b98ef3-75e3-472b-b790-687e3db6d267')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39b98ef3-75e3-472b-b790-687e3db6d267 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_submission",
              "summary": "{\n  \"name\": \"final_submission\",\n  \"rows\": 1100,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1100,\n        \"samples\": [\n          \"TEST_0328\",\n          \"TEST_0688\",\n          \"TEST_0413\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KSBTb6ATPLS_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}