{"cells":[{"cell_type":"markdown","metadata":{"id":"zCu72vDHGMHo"},"source":["## **| 모델 훈련 연습 문제**\n","___\n","- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n","- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."]},{"cell_type":"markdown","metadata":{"id":"j3g-_Dq9GiuT"},"source":["### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n","___\n"]},{"cell_type":"markdown","metadata":{},"source":["확률적 경사 하강법"]},{"cell_type":"markdown","metadata":{"id":"-pDjW5XcHPOt"},"source":["### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n","___"]},{"cell_type":"markdown","metadata":{},"source":["학습률이 클 때이다. 그리드 탐색과 같은 방법으로 적절한 학습률을 찾을 수 있다."]},{"cell_type":"markdown","metadata":{"id":"nM7JbsLoy7b7"},"source":["### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n","___"]},{"cell_type":"markdown","metadata":{},"source":["훈련 오차/검증 오차가 비슷하고 높다면 과소적합 됐다고 볼 수 있다.\n","\n","과소적합은 높은 편향 문제이다.\n","\n","규제 하이퍼 파라미터를 감소시켜서 자유도를 늘려 분산을 키워야 한다."]},{"cell_type":"markdown","metadata":{"id":"C8tARu-ZzOGx"},"source":["### **4. 다음과 같이 사용해야 하는 이유는?**\n","___\n","- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n","\n",": 규제가 있는 모델이 일반적으로 규제가 없는 모델보다 성능이 좋다. 평범한 선형 회귀보다 릿지 회귀가 선호됨.\n","\n","- 릿지 회귀 대신 라쏘 회귀\n","\n",":라쏘 회귀는 l1 패널티를 사용해서 가중치를 완전히 0으로 만드는 경향이 있다. 이는 가장 중요한 가중치를 제외하곤 모두 0이 되는 희소한 모델을 만든다. \n","\n","라쏘 회귀는 자동으로 특성 선택의 효과를 가지므로 단지 몇 개의 특성만 실제 유용할 것이라고 의심될 때 사용하면 좋다. 확신이 없다면 릿지 회귀를 사용해야 한다.\n","\n","- 라쏘 회귀 대신 엘라스틱넷\n","\n",": 라쏘가 어떤 경우(몇 개의 특성이 강한 상관관계가 있거나 훈련 샘플보다 특성이 더 많을 때)에는 불규칙하게 행동하므로 엘라스틱넷이 라쏘보다 일반적으로 선호된다. 그러나 추가적인 하이퍼 파라미터가 생긴다.\n","\n","라쏘를 원한다면 차라리 엘라스틱 넷에 l1_ratio를 1에 가깝게 설정해서 사용하는 편이 좋다."]},{"cell_type":"markdown","metadata":{"id":"QIZpOEYJVIAV"},"source":["### **추가) 조기 종료를 사용한 배치 경사 하강법으로 iris 데이터를 활용해 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요)**\n","\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","from sklearn import datasets\n","\n","iris = datasets.load_iris()\n","\n","X = iris[\"data\"][:, (2,3)] # 꽃잎 길이, 꽃잎 너비\n","y = iris[\"target\"]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Add Bias\n","X_with_bias = np.c_[np.ones([len(X),1]),X]   \n","# len(X) 개수 만큼 1로 채워진 [ ], [ ]......[ ] array\n","# 2열 -> 3열로 늘어남"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# 결과를 일정하게 하기 위해, random seed 배정\n","np.random.seed(1234)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# 원래면 sklearn의 train_test_split을 사용하지만, 직접 만들면서 원리 이해하기\n","test_ratio = 0.2\n","validation_ratio = 0.2\n","total_size = len(X_with_bias)\n","\n","test_size = int(total_size * test_ratio)\n","validation_size = int(total_size * validation_ratio)\n","train_size = total_size - test_size - validation_size\n","\n","rnd_indices = np.random.permutation(total_size)    # 150을 무작위로 섞음 \n","\n","X_train = X_with_bias[rnd_indices[:train_size]]\n","y_train = y[rnd_indices[:train_size]]\n","X_valid = X_with_bias[rnd_indices[train_size:-test_size]]  # test_size 만큼 남겨둠\n","y_valid = y[rnd_indices[train_size:-test_size]]\n","X_test = X_with_bias[rnd_indices[-test_size:]]   \n","y_test = y[rnd_indices[-test_size:]]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# 클래스를 OneHot Vector로 바꾸기 \n","def to_one_hot(y):\n","    n_classes = y.max()+1    # 0,1,2 라 max=2 / +1 하면 classes 개수\n","    m = len(y)                     # 총 150개의 라벨들\n","    y_one_hot = np.zeros((m,n_classes))\n","    y_one_hot[np.arange(m),y] = 1   # index의 행중에 y값을 1로 치환\n","    return y_one_hot"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 1, 2, 0, 1, 0, 0, 0, 1, 2])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["y_train[:10]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["to_one_hot(y_train[:10])   # one hot encoding이 된 것을 확인할 수 있다."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# 라벨 전부를 onehot encoding하기\n","y_train_one_hot = to_one_hot(y_train)\n","y_valid_one_hot = to_one_hot(y_valid)\n","y_test_one_hot = to_one_hot(y_test)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Softmax 함수 만들기\n","\n","def softmax(logits):\n","    exps = np.exp(logits)\n","    exp_sums = np.sum(exps, axis=1, keepdims=True)   # axis=1   ->  가장 안쪽의 [ ] 안의 성분의 합 / 각 exps들의 합\n","    return exps/exp_sums"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# 입력과 출력의 갯수 정하기\n","n_inputs = X_train.shape[1]   # (90,3) 인데 1로 인덱싱 ==3\n","n_outputs = len(np.unique(y_train))  # y_train값을 중복되지 않는 값들을 출력  3"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 3.1114915802681646\n","500 0.8785451855619316\n","1000 0.7103533106437264\n","1500 0.6136193727911318\n","2000 0.5518526140625929\n","2500 0.5086585463656746\n","3000 0.4762907516068719\n","3500 0.45076167129780975\n","4000 0.42984346695974646\n","4500 0.41220116725499784\n","5000 0.39698683289431375\n"]}],"source":["eta = 0.01\n","n_iteration = 5001\n","m = len(X_train)\n","epsilon = 1e-7 # ε : 입실론     nan값을 피하기 위해 logPi에 추가.\n","\n","Theta = np.random.randn(n_inputs, n_outputs)\n","\n","for i in range(n_iteration):\n","    logits = X_train.dot(Theta)\n","    Y_proba = softmax(logits)\n","    loss = -np.mean(np.sum(y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n","    error = Y_proba - y_train_one_hot\n","    if i % 500 == 0:\n","        print(i, loss)\n","    gradients = 1/m * X_train.T.dot(error)\n","    Theta = Theta - eta * gradients "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 2.68979228, -0.7826269 , -2.70314023],\n","       [-0.39955204,  0.45023269,  0.05089443],\n","       [-2.42533074, -0.66589863,  1.80156464]])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# 모델 파라미터 확인\n","Theta"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 6.16011312787746\n","500 0.5381915921349654\n","1000 0.5095758993269639\n","1500 0.5010366468172979\n","2000 0.4979119562128651\n","2500 0.49666869555934534\n","3000 0.496152187705373\n","3500 0.4959322216041512\n","4000 0.4958371221796376\n","4500 0.49579561586140375\n","5000 0.4957773898589144\n"]}],"source":["eta = 0.1\n","n_iteration = 5001\n","m = len(X_train)\n","epilson = 1e-7\n","alpha = 0.1  # 규제 파라미터 \n","\n","Theta = np.random.randn(n_inputs,n_outputs)\n","\n","for i in range(n_iteration):\n","    logits = X_train.dot(Theta)\n","    Y_proba = softmax(logits)\n","    entropy_loss = -np.mean(np.sum(y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n","    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n","    loss = entropy_loss + alpha * l2_loss\n","    error = Y_proba - y_train_one_hot\n","    if i % 500 == 0:\n","        print(i,loss)\n","    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1,n_outputs]), alpha * Theta[1:]]\n","    Theta = Theta - eta * gradients"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3049 0.5616512636635279\n","3050 0.5616512637202469 Early Stopping!\n"]}],"source":["# 조기 종료 추가\n","eta = 0.1\n","m = len(X_train)\n","iteration= 5001\n","epsilon = 1e-7\n","alpha = 0.1\n","best_loss = np.infty\n","\n","Theta = np.random.randn(n_inputs,n_outputs)\n","\n","for i in range(iteration):\n","    logits = X_train.dot(Theta)\n","    Y_proba = softmax(logits)\n","    entropy_loss = -np.mean(np.sum(y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n","    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n","    loss = entropy_loss + alpha * l2_loss\n","    error = Y_proba - y_train_one_hot\n","    gradients = 1/m * X_train.T.dot(error) + np.r_[(np.zeros([1,n_outputs]),alpha * Theta[1:])]\n","    Theta = Theta - eta * gradients\n","    \n","    logits = X_valid.dot(Theta)\n","    Y_proba = softmax(logits)\n","    xentropy_loss = -np.mean(np.sum(y_valid_one_hot * np.log(Y_proba + epsilon), axis=1))\n","    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n","    loss = xentropy_loss + alpha * l2_loss\n","    if iteration % 500 == 0:\n","        print(i,loss)\n","    if loss < best_loss:\n","        best_loss = loss\n","    else:\n","        print(i-1, best_loss)\n","        print(i,loss,\"Early Stopping!\")\n","        break"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["0.9333333333333333"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["logits = X_valid.dot(Theta)\n","Y_proba = softmax(logits)\n","y_predict = np.argmax(Y_proba, axis=1)\n","\n","accuracy_score = np.mean(y_predict == y_valid)\n","accuracy_score\n","\n","# 학습이 더 빠르게 종료되었다. "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
